version: '3.8'

services:
  # PostgreSQL 16 with pgvector extension
  postgres:
    image: pgvector/pgvector:pg16
    container_name: ai-customer-service-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ai_customer_service
      POSTGRES_USER: ai_agent
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-SecurePass123!}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --lc-collate=en_US.utf8 --lc-ctype=en_US.utf8"
      PGDATA: /var/lib/postgresql/data
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database_schema.sql:/docker-entrypoint-initdb.d/01-schema.sql
      - ./docker/postgres/init-extensions.sql:/docker-entrypoint-initdb.d/02-extensions.sql
      - ./docker/postgres/custom-config.conf:/etc/postgresql/postgresql.conf
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ai_agent -d ai_customer_service"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - ai-customer-service

  redis:
    image: redis:7-alpine
    container_name: ai-customer-service-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    networks:
      - ai-customer-service

  elasticsearch:
    image: elastic/elasticsearch:9.1.3
    container_name: ai-customer-service-elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - cluster.name=ai-customer-service
      - node.name=es01
    ports:
      - "${ELASTICSEARCH_PORT:-9200}:9200"
      - "${ELASTICSEARCH_TRANSPORT_PORT:-9300}:9300"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - ai-customer-service

  neo4j:
    image: neo4j:5.15.0
    container_name: ai-customer-service-neo4j
    restart: unless-stopped
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD:-SecureNeo4j123!}
      - NEO4J_PLUGINS=["apoc", "graph-data-science"]
      - NEO4J_dbms_memory_heap_initial__size=512m
      - NEO4J_dbms_memory_heap_max__size=512m
      - "NEO4J_dbms_memory_pagecache_size=256m"
    ports:
      - "${NEO4J_BOLT_PORT:-7687}:7687"
      - "${NEO4J_HTTP_PORT:-7474}:7474"
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    healthcheck:
      test: ["CMD", "neo4j", "status"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - ai-customer-service

  mongodb:
    image: mongo:7.0.5
    container_name: ai-customer-service-mongodb
    restart: unless-stopped
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: ${MONGODB_PASSWORD:-SecureMongo123!}
      MONGO_INITDB_DATABASE: ai_customer_service
    ports:
      - "${MONGODB_PORT:-27017}:27017"
    volumes:
      - mongodb_data:/data/db
    command: mongod --auth
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ai-customer-service

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.1
    container_name: ai-customer-service-zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "${ZOOKEEPER_PORT:-2181}:2181"
    networks:
      - ai-customer-service

  kafka:
    image: confluentinc/cp-kafka:7.5.1
    container_name: ai-customer-service-kafka
    restart: unless-stopped
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    ports:
      - "${KAFKA_PORT:-9092}:9092"
      - "${KAFKA_HOST_PORT:-29092}:29092"
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - ai-customer-service

  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-customer-service-api
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      neo4j:
        condition: service_healthy
      mongodb:
        condition: service_healthy
      kafka:
        condition: service_healthy
    environment:
      - ENVIRONMENT=development
      - LOG_LEVEL=INFO
      - DATASTORE__DATABASE_URL=postgresql+asyncpg://ai_agent:${POSTGRES_PASSWORD:-SecurePass123!}@postgres:5432/ai_customer_service
      - DATASTORE__REDIS_URL=redis://redis:6379/0
      - ELASTICSEARCH__URL=http://elasticsearch:9200
      - NEO4J__URL=bolt://neo4j:${NEO4J_PASSWORD:-SecureNeo4j123!}@neo4j:7687
      - MONGODB__URL=mongodb://admin:${MONGODB_PASSWORD:-SecureMongo123!}@mongodb:27017/ai_customer_service?authSource=admin
      - KAFKA__BOOTSTRAP_SERVERS=kafka:9092
      - SECURITY__SECRET_KEY=${SECRET_KEY:-your-secret-key-here}
      - SECURITY__ENCRYPTION_KEY=${ENCRYPTION_KEY:-your-encryption-key-here}
      - SECURITY__HMAC_SECRET=${HMAC_SECRET:-your-hmac-secret-here}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - PINECONE_ENVIRONMENT=${PINECONE_ENVIRONMENT}
      - DATADOG_API_KEY=${DATADOG_API_KEY}
      - PAGERDUTY_INTEGRATION_KEY=${PAGERDUTY_INTEGRATION_KEY}
    ports:
      - "${API_PORT:-8000}:8000"
    volumes:
      - ./src:/app/src
      - ./tests:/app/tests
      - ./logs:/app/logs
    # Healthcheck is defined in Dockerfile to avoid duplication
    networks:
      - ai-customer-service

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  elasticsearch_data:
    driver: local
  neo4j_data:
    driver: local
  neo4j_logs:
    driver: local
  mongodb_data:
    driver: local
  kafka_data:
    driver: local

networks:
  ai-customer-service:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

